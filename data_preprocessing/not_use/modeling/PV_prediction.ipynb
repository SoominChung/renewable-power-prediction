{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 12947,
     "status": "ok",
     "timestamp": 1746686597430,
     "user": {
      "displayName": "정수민",
      "userId": "03189700386772877231"
     },
     "user_tz": -540
    },
    "id": "MVwABpSM_rAG"
   },
   "outputs": [],
   "source": [
    "import os, random, yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjCvGAS3DQVJ"
   },
   "source": [
    "https://wandb.ai/soomin200-seoul-national-university/solar_prediction?nw=nwusersoomin200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHJeRc7XgwYT"
   },
   "source": [
    "#### Setting Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1746689507496,
     "user": {
      "displayName": "정수민",
      "userId": "03189700386772877231"
     },
     "user_tz": -540
    },
    "id": "d_kih2UMzRkt",
    "outputId": "531bd2ae-0fb3-4c35-ba1d-5212e7fd086e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/soomin/공공데이터분석공모전/renewable-power-prediction\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/soomin/공공데이터분석공모전/renewable-power-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12965,
     "status": "ok",
     "timestamp": 1746689521290,
     "user": {
      "displayName": "정수민",
      "userId": "03189700386772877231"
     },
     "user_tz": -540
    },
    "id": "FcYruyLbgzWz",
    "outputId": "59a4651f-1680-4084-f11b-492640ee28f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refresh index: 100% (9/9), done.\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   PV_prediction.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m\"data/futureweather\\341\\204\\221\\341\\205\\241\\341\\204\\213\\341\\205\\265\\341\\206\\257.md\"\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpHTqvligvIJ"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1746686731173,
     "user": {
      "displayName": "정수민",
      "userId": "03189700386772877231"
     },
     "user_tz": -540
    },
    "id": "RuavEpRnexcu",
    "outputId": "ff0e2d60-bb9a-4a4d-9e9d-8fa8d99de2d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부산신항태양광 발전용량 (kW):  115.0\n"
     ]
    }
   ],
   "source": [
    "meta_data = pd.read_csv('/content/drive/MyDrive/soomin/공공데이터분석공모전/data/raw_data/한국남부발전(주)_에너지원별 신재생에너지 발전설비 현황_20250312.csv',encoding='cp949')\n",
    "sun = meta_data[meta_data['에너지원']=='태양광']\n",
    "plant_capacity = sun[sun['발전소명']=='부산신항태양광']['용량(MW)'].iloc[0]*1000\n",
    "print('부산신항태양광 발전용량 (kW): ',plant_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1746688883135,
     "user": {
      "displayName": "정수민",
      "userId": "03189700386772877231"
     },
     "user_tz": -540
    },
    "id": "Lo-A7gVFX_gQ",
    "outputId": "0a6b10e5-bade-495a-b7c4-a37a9496b1b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "# config.yaml\n",
    "\n",
    "# ─── 데이터 파라미터 ──────────────────────────────\n",
    "data:\n",
    "  root: \"/content/drive/MyDrive/soomin/공공데이터분석공모전/data/raw_data/한국남부발전(주)_부산신항 태양광발전실적_20250228.csv\"\n",
    "  train_ratio: 0.7\n",
    "  val_ratio:   0.1\n",
    "  test_ratio:  0.2\n",
    "  # 윈도우 크기(일), 예측 대상 크기(일)\n",
    "  window_size:     10\n",
    "  prediction_size: 1\n",
    "  # 입력 스케일링 방식\n",
    "  scaler: \"StandardScaler\"\n",
    "\n",
    "\n",
    "# ─── 모델 구조 파라미터 ──────────────────────────────\n",
    "model:\n",
    "  name: \"solar_prediction\"\n",
    "  # 사용할 모델 종류: \"LSTM\" 또는 \"Transformer\"\n",
    "  type: \"Transformer\"\n",
    "  # LSTM 전용\n",
    "  hidden_size: 128\n",
    "  num_layers: 3\n",
    "  # Transformer 전용\n",
    "  d_model: 128\n",
    "  nhead: 8\n",
    "  num_layers_trf: 2\n",
    "\n",
    "# ─── 학습 파라미터 ──────────────────────────────\n",
    "training:\n",
    "  seed:            42\n",
    "  learning_rate:   1e-3\n",
    "  batch_size:      32\n",
    "  epochs:          200\n",
    "  # 옵티마이저/스케줄러 이름과 추가 파라미터\n",
    "  optimizer:       \"Adam\"\n",
    "  optimizer_params:\n",
    "    weight_decay:  0.0\n",
    "    amsgrad:       false\n",
    "  scheduler:       \"CosineAnnealingLR\"\n",
    "  scheduler_params:\n",
    "    T_max:         200\n",
    "    eta_min:       0.0\n",
    "  # 사용할 loss 종류: \"prediction_error_rate_loss\" or \"MSELoss\" or .....\n",
    "  loss:         \"MSELoss\"\n",
    "  # 얼리 스톱 옵션\n",
    "  early_stopping:\n",
    "    use:           true\n",
    "    patience:      20\n",
    "\n",
    "# ─── W&B 설정 ──────────────────────────────\n",
    "wandb:\n",
    "  api_key:      \"a8af4997e63da6343549fc1212570a2d1c274303\"\n",
    "  entity:       \"soomin200-seoul-national-university\"\n",
    "  project:      \"solar_prediction\"\n",
    "  # run name 에 포함할 항목\n",
    "  run_name_params:\n",
    "    - optimizer\n",
    "    - scheduler\n",
    "    - learning_rate\n",
    "    - window_size\n",
    "    - loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 101200,
     "status": "ok",
     "timestamp": 1746688984436,
     "user": {
      "displayName": "정수민",
      "userId": "03189700386772877231"
     },
     "user_tz": -540
    },
    "id": "HHcbJdfkaWoW",
    "outputId": "819ac761-0e8e-47d0-eb71-555b203af211"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250508_072123-r3fjus7y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/soomin200-seoul-national-university/solar_prediction/runs/r3fjus7y' target=\"_blank\">Transformer_optAdam_schCosineAnnealingLR_lea1e-3_win10_losMSELoss</a></strong> to <a href='https://wandb.ai/soomin200-seoul-national-university/solar_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/soomin200-seoul-national-university/solar_prediction' target=\"_blank\">https://wandb.ai/soomin200-seoul-national-university/solar_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/soomin200-seoul-national-university/solar_prediction/runs/r3fjus7y' target=\"_blank\">https://wandb.ai/soomin200-seoul-national-university/solar_prediction/runs/r3fjus7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerRegressor(\n",
      "  (embed): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (trf): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=24, bias=True)\n",
      ")\n",
      "Early stopping at epoch 28\n",
      "[Transformer] Test Loss = 50.8314\n",
      "Sample Test Results (first 5):\n",
      " Sample 1:\n",
      "  Predicted: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '3.34', '14.25', '27.24', '37.06', '43.50', '44.96', '42.55', '35.79', '25.94', '13.88', '3.48', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "  Actual   : ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '3.24', '9.36', '10.92', '10.32', '19.44', '26.40', '19.32', '10.44', '8.40', '2.28', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "  10% 구간만:\n",
      "   Predicted: ['43.50', '44.96', '42.55']\n",
      "   Actual   : ['19.44', '26.40', '19.32']\n",
      "   ErrorRate: 57.27%\n",
      "  ------------------------------\n",
      " Sample 2:\n",
      "  Predicted: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '2.91', '13.61', '26.51', '36.32', '42.78', '44.24', '41.81', '35.05', '25.22', '13.26', '3.07', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "  Actual   : ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '3.72', '5.52', '16.92', '17.76', '19.08', '28.92', '28.44', '27.24', '18.84', '16.32', '3.36', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "  10% 구간만:\n",
      "   Predicted: ['26.51', '36.32', '42.78', '44.24', '41.81', '35.05', '25.22', '13.26']\n",
      "   Actual   : ['16.92', '17.76', '19.08', '28.92', '28.44', '27.24', '18.84', '16.32']\n",
      "   ErrorRate: 85.05%\n",
      "  ------------------------------\n",
      " Sample 3:\n",
      "  Predicted: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '2.82', '13.47', '26.36', '36.16', '42.64', '44.09', '41.66', '34.90', '25.07', '13.12', '2.98', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "  Actual   : ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '3.12', '13.08', '25.56', '29.64', '37.20', '49.08', '23.04', '13.92', '14.28', '7.32', '0.48', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "  10% 구간만:\n",
      "   Predicted: ['13.47', '26.36', '36.16', '42.64', '44.09', '41.66', '34.90', '25.07']\n",
      "   Actual   : ['13.08', '25.56', '29.64', '37.20', '49.08', '23.04', '13.92', '14.28']\n",
      "   ErrorRate: 59.60%\n",
      "  ------------------------------\n",
      " Sample 4:\n",
      "  Predicted: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '2.76', '13.38', '26.25', '36.05', '42.53', '43.98', '41.54', '34.78', '24.96', '13.03', '2.92', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "  Actual   : ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '6.24', '21.36', '32.76', '41.52', '48.00', '49.92', '45.96', '38.40', '28.44', '16.20', '3.24', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "  10% 구간만:\n",
      "   Predicted: ['13.38', '26.25', '36.05', '42.53', '43.98', '41.54', '34.78', '24.96', '13.03']\n",
      "   Actual   : ['21.36', '32.76', '41.52', '48.00', '49.92', '45.96', '38.40', '28.44', '16.20']\n",
      "   ErrorRate: 40.05%\n",
      "  ------------------------------\n",
      " Sample 5:\n",
      "  Predicted: ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '2.80', '13.45', '26.33', '36.13', '42.60', '44.06', '41.62', '34.86', '25.04', '13.10', '2.97', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "  Actual   : ['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '5.76', '18.96', '31.80', '41.28', '46.08', '48.24', '45.00', '38.16', '27.24', '14.16', '2.64', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "  10% 구간만:\n",
      "   Predicted: ['13.45', '26.33', '36.13', '42.60', '44.06', '41.62', '34.86', '25.04', '13.10']\n",
      "   Actual   : ['18.96', '31.80', '41.28', '46.08', '48.24', '45.00', '38.16', '27.24', '14.16']\n",
      "   ErrorRate: 29.33%\n",
      "  ------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>28</td></tr><tr><td>test_loss</td><td>50.83142</td></tr><tr><td>train_loss</td><td>115.40434</td></tr><tr><td>val_loss</td><td>99.36723</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Transformer_optAdam_schCosineAnnealingLR_lea1e-3_win10_losMSELoss</strong> at: <a href='https://wandb.ai/soomin200-seoul-national-university/solar_prediction/runs/r3fjus7y' target=\"_blank\">https://wandb.ai/soomin200-seoul-national-university/solar_prediction/runs/r3fjus7y</a><br> View project at: <a href='https://wandb.ai/soomin200-seoul-national-university/solar_prediction' target=\"_blank\">https://wandb.ai/soomin200-seoul-national-university/solar_prediction</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_072123-r3fjus7y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ─── 0) 설정 로드 및 W&B 인증 ───────────────────────────\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# W&B 환경 변수 (config.yaml)\n",
    "os.environ[\"WANDB_API_KEY\"] = cfg[\"wandb\"][\"api_key\"]\n",
    "os.environ[\"WANDB_ENTITY\"]  = cfg[\"wandb\"][\"entity\"]\n",
    "os.environ[\"WANDB_PROJECT\"] = cfg[\"wandb\"][\"project\"]\n",
    "wandb.login(key=os.environ[\"WANDB_API_KEY\"], relogin=True)\n",
    "\n",
    "# ─── 1) 시드 & 장치 설정 ─────────────────────────────────\n",
    "seed = cfg[\"training\"][\"seed\"]\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "DEVICE = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() and cfg[\"training\"].get(\"device\", \"cuda\") == \"cuda\"\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# ─── 2) 하이퍼파라미터 ───────────────────────────────────\n",
    "LR         = float(cfg[\"training\"][\"learning_rate\"])\n",
    "BATCH_SIZE = int(cfg[\"training\"][\"batch_size\"])\n",
    "EPOCHS     = int(cfg[\"training\"][\"epochs\"])\n",
    "\n",
    "# ─── 3) 데이터 준비 함수 ─────────────────────────────────\n",
    "def prepare_data(df):\n",
    "    # 날짜형 변환 & 정렬\n",
    "    df[\"년월일\"] = pd.to_datetime(df[\"년월일\"])\n",
    "    df = df.sort_values(\"년월일\").reset_index(drop=True)\n",
    "\n",
    "    hourly = df[[str(h) for h in range(1, 25)]].values\n",
    "    ws = cfg[\"data\"][\"window_size\"]\n",
    "    ps = cfg[\"data\"][\"prediction_size\"]\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(hourly) - ws - ps + 1):\n",
    "        inp = hourly[i : i+ws].reshape(-1)\n",
    "        out = hourly[i+ws : i+ws+ps].reshape(-1)\n",
    "        X.append(inp)\n",
    "        y.append(out)\n",
    "\n",
    "    X = np.stack(X)\n",
    "    y = np.stack(y)\n",
    "\n",
    "    # split ratios\n",
    "    tr, va, _ = cfg[\"data\"][\"train_ratio\"], cfg[\"data\"][\"val_ratio\"], cfg[\"data\"][\"test_ratio\"]\n",
    "    n = len(X)\n",
    "    n_tr = int(tr * n)\n",
    "    n_va = int(va * n)\n",
    "\n",
    "    X_tr, y_tr = X[:n_tr],    y[:n_tr]\n",
    "    X_va, y_va = X[n_tr:n_tr+n_va], y[n_tr:n_tr+n_va]\n",
    "    X_te, y_te = X[n_tr+n_va:],      y[n_tr+n_va:]\n",
    "\n",
    "    # scaling\n",
    "    if cfg[\"data\"][\"scaler\"] == \"StandardScaler\":\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(X_tr)\n",
    "        X_va = scaler.transform(X_va)\n",
    "        X_te = scaler.transform(X_te)\n",
    "\n",
    "    return (X_tr, y_tr), (X_va, y_va), (X_te, y_te)\n",
    "\n",
    "# ─── 4) DataLoader 생성 ─────────────────────────────────\n",
    "def make_loader(X, y, shuffle=False):\n",
    "    tx = torch.tensor(X, dtype=torch.float32)\n",
    "    ty = torch.tensor(y, dtype=torch.float32)\n",
    "    ds = TensorDataset(tx, ty)\n",
    "    return DataLoader(ds, batch_size=BATCH_SIZE, shuffle=shuffle)\n",
    "\n",
    "# ─── 5) 모델 정의 ───────────────────────────────────────\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        hs = cfg[\"model\"][\"hidden_size\"]\n",
    "        nl = cfg[\"model\"][\"num_layers\"]\n",
    "        self.lstm = nn.LSTM(1, hs, nl, batch_first=True)\n",
    "        self.fc   = nn.Linear(hs, cfg[\"data\"][\"prediction_size\"] * 24)\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return torch.relu(out)\n",
    "\n",
    "class TransformerRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        dm = cfg[\"model\"][\"d_model\"]\n",
    "        nh = cfg[\"model\"][\"nhead\"]\n",
    "        nl = cfg[\"model\"][\"num_layers_trf\"]\n",
    "        self.embed = nn.Linear(1, dm)\n",
    "        enc = nn.TransformerEncoderLayer(d_model=dm, nhead=nh, batch_first=True)\n",
    "        self.trf = nn.TransformerEncoder(enc, nl)\n",
    "        self.fc  = nn.Linear(dm, cfg[\"data\"][\"prediction_size\"] * 24)\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)\n",
    "        x = self.embed(x)\n",
    "        x = self.trf(x)\n",
    "        x = x.mean(dim=1)\n",
    "        out = self.fc(x)\n",
    "        return torch.relu(out) # 0 미만 값은 0으로 처리\n",
    "\n",
    "# ─── 6) 학습/평가 함수 ───────────────────────────────────\n",
    "def train_and_evaluate(model_cls, name):\n",
    "    # run name 생성\n",
    "    rn_params = cfg[\"wandb\"][\"run_name_params\"]\n",
    "    vals = {p: cfg[\"training\"].get(p, cfg[\"data\"].get(p, \"\")) for p in rn_params}\n",
    "    run_name = f\"{name}_\" + \"_\".join(f\"{p[:3]}{vals[p]}\" for p in rn_params)\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=cfg[\"wandb\"][\"project\"],\n",
    "        entity=cfg[\"wandb\"][\"entity\"],\n",
    "        name=run_name,\n",
    "        config={**cfg[\"model\"], **cfg[\"training\"], **cfg[\"data\"]}\n",
    "    )\n",
    "\n",
    "    # 데이터 로드\n",
    "    df = pd.read_csv(cfg[\"data\"][\"root\"], encoding=\"cp949\")\n",
    "    splits = prepare_data(df)\n",
    "    train_loader = make_loader(*splits[0], shuffle=True)\n",
    "    val_loader   = make_loader(*splits[1])\n",
    "    test_loader  = make_loader(*splits[2])\n",
    "\n",
    "    model = model_cls().to(DEVICE)\n",
    "    print(model)\n",
    "    wandb.watch(model, log=\"all\", log_freq=100)  # 모델 구조 로깅\n",
    "    opt_cls = getattr(torch.optim, cfg[\"training\"][\"optimizer\"])\n",
    "    optimizer = opt_cls(model.parameters(), lr=LR, **cfg[\"training\"][\"optimizer_params\"])\n",
    "    sch_cls = getattr(torch.optim.lr_scheduler, cfg[\"training\"][\"scheduler\"])\n",
    "    scheduler = sch_cls(optimizer, **cfg[\"training\"][\"scheduler_params\"])\n",
    "    #criterion = nn.MSELoss()\n",
    "    # ── 커스텀 예측오차율 손실 함수 정의 (재생에너지 발전량 예측제도 오차율 참고해서!) ──\n",
    "    def prediction_error_rate_loss(preds, targets):\n",
    "        # preds, targets: (batch, T)\n",
    "        # 1) 설비이용률 10% 이상인 시간대만 마스크 (**** 고민: 설비이용률 10% 이상인 시간대만 loss 계산에 사용하는게 맞을지, 우선 전체 구간에 대한 예측 성능을 개선한 후 후처리로 10% 부분 계산할지. -> 근데 이건 실험 해봐야할듯)\n",
    "        threshold = plant_capacity * 0.1\n",
    "        mask = (targets >= threshold).float()\n",
    "        # 2) 절대 오차 계산\n",
    "        abs_error = torch.abs(targets - preds)\n",
    "        # 3) 시간축 합산 → 표준화(용량) → % 변환 → 샘플별 손실\n",
    "        error_sum   = (abs_error * mask).sum(dim=1)\n",
    "        error_rate  = error_sum / plant_capacity * 100.0\n",
    "        # 4) 배치 평균\n",
    "        return error_rate.mean()\n",
    "    loss_name = cfg[\"training\"][\"loss\"]\n",
    "    if loss_name == \"prediction_error_rate_loss\":\n",
    "      criterion = prediction_error_rate_loss\n",
    "    elif loss_name in [\"MSELoss\", \"L1Loss\", \"SmoothL1Loss\"]:\n",
    "        # nn 모듈 안에 같은 이름으로 정의된 클래스를 바로 불러오도록\n",
    "        criterion_cls = getattr(nn, loss_name)\n",
    "        criterion     = criterion_cls()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss type '{loss_name}' in config.\")\n",
    "\n",
    "    best_val, wait = float(\"inf\"), 0\n",
    "    pat, use_es = cfg[\"training\"][\"early_stopping\"][\"patience\"], cfg[\"training\"][\"early_stopping\"][\"use\"]\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        ### Train\n",
    "        model.train()\n",
    "        tr_losses = []\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            loss = criterion(model(xb), yb)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            tr_losses.append(loss.item())\n",
    "        ### Valid\n",
    "        model.eval()\n",
    "        va_losses = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                pred   = model(xb)\n",
    "                va_losses.append(criterion(pred, yb).item())\n",
    "        avg_tr, avg_va = np.mean(tr_losses), np.mean(va_losses)\n",
    "        wandb.log({\"epoch\": epoch, \"train_loss\": avg_tr, \"val_loss\": avg_va})\n",
    "        scheduler.step()\n",
    "        if avg_va < best_val:\n",
    "            best_val, wait = avg_va, 0\n",
    "            torch.save(model.state_dict(), f\"{name}_best.pth\")\n",
    "        else:\n",
    "            wait += 1\n",
    "            if use_es and wait >= pat:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    # 테스트\n",
    "    model.load_state_dict(torch.load(f\"{name}_best.pth\"))\n",
    "    model.eval()\n",
    "    te_losses = []\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            pred   = model(xb)\n",
    "            all_preds.append(pred.cpu().numpy())\n",
    "            all_targets.append(yb.cpu().numpy())\n",
    "            # prediction_error_rate_loss외에 다른 loss 로 학습하고 test만 prediction_error_rate_loss로 확인해도 되니까\n",
    "            #te_losses.append(criterion(pred, yb).item())\n",
    "            te_losses.append(prediction_error_rate_loss(pred, yb).item())\n",
    "\n",
    "\n",
    "    all_preds   = np.vstack(all_preds)      # shape: (N_test, ps*24)\n",
    "    all_targets = np.vstack(all_targets)    # shape: (N_test, ps*24)\n",
    "    mse = np.mean((all_preds - all_targets)**2)\n",
    "\n",
    "    wandb.log({\"test_loss\": np.mean(te_losses)})\n",
    "    print(f\"[{name}] Test Loss = {np.mean(te_losses):.4f}\")\n",
    "\n",
    "    # ─── Sample Test Results (first 5) ─────────────────────────\n",
    "    threshold_kW = plant_capacity * 0.1\n",
    "\n",
    "    print(\"Sample Test Results (first 5):\")\n",
    "    for i in range(min(5, len(all_preds))):\n",
    "        pred = all_preds[i]        # shape (T,)\n",
    "        act  = all_targets[i]      # shape (T,)\n",
    "\n",
    "        # (1) 전체 출력\n",
    "        pred_fmt   = [f\"{v:.2f}\" for v in pred]\n",
    "        actual_fmt = [f\"{v:.2f}\" for v in act]\n",
    "        print(f\" Sample {i+1}:\")\n",
    "        print(\"  Predicted:\", pred_fmt)\n",
    "        print(\"  Actual   :\", actual_fmt)\n",
    "\n",
    "        # (2) 10% 기준 넘는 시간대만 필터링\n",
    "        mask = act >= threshold_kW\n",
    "        pred_10 = pred[mask]\n",
    "        act_10  = act[mask]\n",
    "        pred10_fmt   = [f\"{v:.2f}\" for v in pred_10]\n",
    "        actual10_fmt = [f\"{v:.2f}\" for v in act_10]\n",
    "        print(\"  10% 구간만:\")\n",
    "        print(\"   Predicted:\", pred10_fmt or [\"(해당 없음)\"])\n",
    "        print(\"   Actual   :\", actual10_fmt or [\"(해당 없음)\"])\n",
    "\n",
    "        # (3) 10% 구간 오차율 계산\n",
    "        if mask.any():\n",
    "            err_sum = np.abs(act_10 - pred_10).sum()\n",
    "            err_rate = err_sum / plant_capacity * 100\n",
    "            print(f\"   ErrorRate: {err_rate:.2f}%\")\n",
    "        else:\n",
    "            print(\"   ErrorRate: N/A (10% 구간 없음)\")\n",
    "\n",
    "        print(\"  \" + \"-\"*30)\n",
    "\n",
    "    run.finish()\n",
    "\n",
    "# ─── 7) 메인 실행 ─────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    # 모델 타입에 따라 실행\n",
    "    if cfg[\"model\"][\"type\"] == \"LSTM\":\n",
    "        train_and_evaluate(LSTMRegressor, \"LSTM\")\n",
    "    elif cfg[\"model\"][\"type\"] == \"Transformer\":\n",
    "        train_and_evaluate(TransformerRegressor, \"Transformer\")\n",
    "    else:\n",
    "        # 둘 다 실행\n",
    "        train_and_evaluate(LSTMRegressor, \"LSTM\")\n",
    "        train_and_evaluate(TransformerRegressor, \"Transformer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "error",
     "timestamp": 1746688300138,
     "user": {
      "displayName": "정수민",
      "userId": "03189700386772877231"
     },
     "user_tz": -540
    },
    "id": "f4qWOsobDN-t",
    "outputId": "5cce5e52-d389-4213-a338-2f0a21f41214"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1f8a688cae5d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOzLdDwZkyd9gqBTykA0XrU",
   "collapsed_sections": [
    "kx0HipJgWx_v"
   ],
   "gpuType": "T4",
   "mount_file_id": "14gyfF653meyKkgFM5wdz7yyQoy0gyPO5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
